{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPr6dFGURCYtBDtvqiMW6r4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StarryNight7210/Bioinformatics---scRNA-Sequencing-Analysis/blob/main/Alzheimer's_Project_data_combiner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import necessary modules"
      ],
      "metadata": {
        "id": "2ykdF9VK2Wjk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HI0abwMX3FM-",
        "outputId": "2604590a-5c7d-46b3-b538-0f611e52da81",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scanpy\n",
            "  Downloading scanpy-1.11.4-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting python-igraph\n",
            "  Downloading python_igraph-0.11.9-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting leidenalg\n",
            "  Downloading leidenalg-0.10.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting anndata>=0.8 (from scanpy)\n",
            "  Downloading anndata-0.12.2-py3-none-any.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: h5py>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from scanpy) (3.14.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from scanpy) (1.5.2)\n",
            "Collecting legacy-api-wrap>=1.4.1 (from scanpy)\n",
            "  Downloading legacy_api_wrap-1.4.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: matplotlib>=3.7.5 in /usr/local/lib/python3.12/dist-packages (from scanpy) (3.10.0)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.12/dist-packages (from scanpy) (8.4.0)\n",
            "Requirement already satisfied: networkx>=2.7.1 in /usr/local/lib/python3.12/dist-packages (from scanpy) (3.5)\n",
            "Requirement already satisfied: numba>=0.57.1 in /usr/local/lib/python3.12/dist-packages (from scanpy) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.24.1 in /usr/local/lib/python3.12/dist-packages (from scanpy) (2.0.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from scanpy) (25.0)\n",
            "Requirement already satisfied: pandas>=1.5.3 in /usr/local/lib/python3.12/dist-packages (from scanpy) (2.2.2)\n",
            "Requirement already satisfied: patsy!=1.0.0 in /usr/local/lib/python3.12/dist-packages (from scanpy) (1.0.1)\n",
            "Requirement already satisfied: pynndescent>=0.5.13 in /usr/local/lib/python3.12/dist-packages (from scanpy) (0.5.13)\n",
            "Requirement already satisfied: scikit-learn>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from scanpy) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from scanpy) (1.16.2)\n",
            "Requirement already satisfied: seaborn>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from scanpy) (0.13.2)\n",
            "Collecting session-info2 (from scanpy)\n",
            "  Downloading session_info2-0.2.3-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: statsmodels>=0.14.5 in /usr/local/lib/python3.12/dist-packages (from scanpy) (0.14.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from scanpy) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from scanpy) (4.15.0)\n",
            "Requirement already satisfied: umap-learn>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from scanpy) (0.5.9.post2)\n",
            "Collecting igraph==0.11.9 (from python-igraph)\n",
            "  Downloading igraph-0.11.9-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Collecting texttable>=1.6.2 (from igraph==0.11.9->python-igraph)\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting array-api-compat>=1.7.1 (from anndata>=0.8->scanpy)\n",
            "  Downloading array_api_compat-1.12.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting zarr!=3.0.*,>=2.18.7 (from anndata>=0.8->scanpy)\n",
            "  Downloading zarr-3.1.3-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.5->scanpy) (2.9.0.post0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.57.1->scanpy) (0.43.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5.3->scanpy) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5.3->scanpy) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.3->scanpy) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7.5->scanpy) (1.17.0)\n",
            "Collecting donfig>=0.8 (from zarr!=3.0.*,>=2.18.7->anndata>=0.8->scanpy)\n",
            "  Downloading donfig-0.8.1.post1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting numcodecs>=0.14 (from numcodecs[crc32c]>=0.14->zarr!=3.0.*,>=2.18.7->anndata>=0.8->scanpy)\n",
            "  Downloading numcodecs-0.16.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from donfig>=0.8->zarr!=3.0.*,>=2.18.7->anndata>=0.8->scanpy) (6.0.3)\n",
            "Collecting crc32c>=2.7 (from numcodecs[crc32c]>=0.14->zarr!=3.0.*,>=2.18.7->anndata>=0.8->scanpy)\n",
            "  Downloading crc32c-2.7.1.post0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (7.4 kB)\n",
            "Downloading scanpy-1.11.4-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_igraph-0.11.9-py3-none-any.whl (9.2 kB)\n",
            "Downloading igraph-0.11.9-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading leidenalg-0.10.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anndata-0.12.2-py3-none-any.whl (169 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.9/169.9 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading legacy_api_wrap-1.4.1-py3-none-any.whl (10.0 kB)\n",
            "Downloading session_info2-0.2.3-py3-none-any.whl (16 kB)\n",
            "Downloading array_api_compat-1.12.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.2/58.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading zarr-3.1.3-py3-none-any.whl (276 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.4/276.4 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading donfig-0.8.1.post1-py3-none-any.whl (21 kB)\n",
            "Downloading numcodecs-0.16.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading crc32c-2.7.1.post0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: texttable, session-info2, numcodecs, legacy-api-wrap, igraph, donfig, crc32c, array-api-compat, python-igraph, leidenalg, zarr, anndata, scanpy\n",
            "Successfully installed anndata-0.12.2 array-api-compat-1.12.0 crc32c-2.7.1.post0 donfig-0.8.1.post1 igraph-0.11.9 legacy-api-wrap-1.4.1 leidenalg-0.10.2 numcodecs-0.16.3 python-igraph-0.11.9 scanpy-1.11.4 session-info2-0.2.3 texttable-1.7.0 zarr-3.1.3\n"
          ]
        }
      ],
      "source": [
        "%pip install scanpy python-igraph leidenalg\n",
        "\n",
        "# import packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scanpy as sc\n",
        "from scipy import sparse\n",
        "import os\n",
        "import gc\n",
        "\n",
        "sc.settings.verbosity = 3   # verbosity: errors (0), warnings (1), info (2), hints (3)\n",
        "\n",
        "# customize resolution and color of your figures\n",
        "sc.settings.set_figure_params(dpi=80, figsize=(4,4))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get ready to store data"
      ],
      "metadata": {
        "id": "6KHC05P62fqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (!) Shell commands for creating folder and storing data\n",
        "\n",
        "# Create a folder ()\n",
        "!mkdir my_data\n",
        "# Download count file from web (wget) and save to file named my_counts\n",
        "!wget -O my_data/my_counts.tar \"https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE175814&format=file\""
      ],
      "metadata": {
        "id": "U7fMdhy75eOs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "b713d72c-96e9-41a2-be7b-9b83a064dd77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-15 23:42:39--  https://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE175814&format=file\n",
            "Resolving www.ncbi.nlm.nih.gov (www.ncbi.nlm.nih.gov)... 130.14.29.110, 2607:f220:41e:4290::110\n",
            "Connecting to www.ncbi.nlm.nih.gov (www.ncbi.nlm.nih.gov)|130.14.29.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 284180480 (271M) [application/x-tar]\n",
            "Saving to: ‘my_data/my_counts.tar’\n",
            "\n",
            "my_data/my_counts.t 100%[===================>] 271.02M  29.8MB/s    in 7.2s    \n",
            "\n",
            "2025-10-15 23:42:47 (37.8 MB/s) - ‘my_data/my_counts.tar’ saved [284180480/284180480]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "result = subprocess.run([\"tar\", \"-xvf\", \"my_data/my_counts.tar\"], capture_output=True, text=True)\n"
      ],
      "metadata": {
        "id": "yqyzdkahnMD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the data from the online source, and compile into data frames, one for each patient"
      ],
      "metadata": {
        "id": "KcUDZFT32qD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.io import mmread\n",
        "\n",
        "# Load the count matrix\n",
        "counts1 = mmread(\"/content/GSM5348374_A1_matrix.mtx.gz\").tocsc()\n",
        "\n",
        "# Load features (genes)\n",
        "features1 = pd.read_csv(\"/content/GSM5348374_A1_features.tsv.gz\", header=None, sep=\"\\t\")\n",
        "genes1 = features1[1].values  # second column usually has gene symbols\n",
        "\n",
        "# Load barcodes (cells)\n",
        "barcodes1 = pd.read_csv(\"/content/GSM5348374_A1_barcodes.tsv.gz\", header=None, sep=\"\\t\")\n",
        "cells1 = barcodes1[0].values\n",
        "\n",
        "# Build a DataFrame: rows = genes, columns = cells\n",
        "counts_df1 = pd.DataFrame.sparse.from_spmatrix(counts1).T\n",
        "counts_df1.index = cells1\n",
        "counts_df1.columns = genes1\n",
        "\n",
        "# Load the count matrix\n",
        "counts2 = mmread(\"/content/GSM5348375_A2_matrix.mtx.gz\").tocsc()\n",
        "\n",
        "# Load features (genes)\n",
        "features2 = pd.read_csv(\"/content/GSM5348375_A2_features.tsv.gz\", header=None, sep=\"\\t\")\n",
        "genes2 = features2[1].values  # second column usually has gene symbols\n",
        "\n",
        "# Load barcodes (cells)\n",
        "barcodes2 = pd.read_csv(\"/content/GSM5348375_A2_barcodes.tsv.gz\", header=None, sep=\"\\t\")\n",
        "cells2 = barcodes2[0].values\n",
        "\n",
        "# Build a DataFrame: rows = genes, columns = cells\n",
        "counts_df2 = pd.DataFrame.sparse.from_spmatrix(counts2).T\n",
        "counts_df2.index = cells2\n",
        "counts_df2.columns = genes2\n",
        "\n",
        "# Load the count matrix\n",
        "counts3 = mmread(\"/content/GSM5348376_A3_matrix.mtx.gz\").tocsc()\n",
        "\n",
        "# Load features (genes)\n",
        "features3 = pd.read_csv(\"/content/GSM5348376_A3_features.tsv.gz\", header=None, sep=\"\\t\")\n",
        "genes3 = features3[1].values  # second column usually has gene symbols\n",
        "\n",
        "# Load barcodes (cells)\n",
        "barcodes3 = pd.read_csv(\"/content/GSM5348376_A3_barcodes.tsv.gz\", header=None, sep=\"\\t\")\n",
        "cells3 = barcodes3[0].values\n",
        "\n",
        "# Build a DataFrame: rows = genes, columns = cells\n",
        "counts_df3 = pd.DataFrame.sparse.from_spmatrix(counts3).T\n",
        "counts_df3.index = cells3\n",
        "counts_df3.columns = genes3\n",
        "\n",
        "# Load the count matrix\n",
        "counts4 = mmread(\"/content/GSM5348377_A4_matrix.mtx.gz\").tocsc()\n",
        "\n",
        "# Load features (genes)\n",
        "features4 = pd.read_csv(\"/content/GSM5348377_A4_features.tsv.gz\", header=None, sep=\"\\t\")\n",
        "genes4 = features4[1].values  # second column usually has gene symbols\n",
        "\n",
        "# Load barcodes (cells)\n",
        "barcodes4 = pd.read_csv(\"/content/GSM5348377_A4_barcodes.tsv.gz\", header=None, sep=\"\\t\")\n",
        "cells4 = barcodes4[0].values\n",
        "\n",
        "# Build a DataFrame: rows = genes, columns = cells\n",
        "counts_df4 = pd.DataFrame.sparse.from_spmatrix(counts4).T\n",
        "counts_df4.index = cells4\n",
        "counts_df4.columns = genes4"
      ],
      "metadata": {
        "id": "PbpzYPSdnkcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assign sources and make combined data frames for patients 1 and 2 and patients 3 and 4"
      ],
      "metadata": {
        "id": "YkKvd1dI2uI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Before making combined data frames, label each patient's data with which patient it came from\n",
        "# So that once the data is combined, we can still see what data came from where\n",
        "\n",
        "counts_df1[\"Source\"] = 1\n",
        "counts_df2[\"Source\"] = 2\n",
        "\n",
        "counts_df3[\"Source\"] = 3\n",
        "counts_df4[\"Source\"] = 4\n",
        "\n",
        "# Make the combined data frames\n",
        "\n",
        "counts_df_A = pd.concat([counts_df1, counts_df2], ignore_index=False)\n",
        "counts_df_B = pd.concat([counts_df3, counts_df4], ignore_index=False)"
      ],
      "metadata": {
        "id": "_u50sfzA2OYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Randomly sample half of each of the combined data frames"
      ],
      "metadata": {
        "id": "YUHHM4dV3Btq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "proportion = 0.5\n",
        "\n",
        "sampled_df_A = counts_df_A.sample(n= int(proportion * counts_df_A.shape[0]), random_state=42)\n",
        "sampled_df_B = counts_df_B.sample(n= int(proportion * counts_df_B.shape[0]), random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uvPbMRtP-Yn",
        "outputId": "06d60955-86da-4461-c137-ad42719e550a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6242, 33539)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine the two data frames so that we have all 4 patients in one data frame but only half the data, so we don't exceed RAM limits"
      ],
      "metadata": {
        "id": "3YyVDC0v3I7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "counts_df = pd.concat([sampled_df_A, sampled_df_B], ignore_index=False)"
      ],
      "metadata": {
        "id": "MtU9vT9SSMgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Export to Google Drive"
      ],
      "metadata": {
        "id": "euighiTE3QP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "counts_df.to_pickle('/content/drive/MyDrive/counts_df.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50EGhnulR_2i",
        "outputId": "174d4285-ea1d-45eb-d49f-2327dfe02eca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    }
  ]
}